Problem Statement_Yaoli_talk and engagementVersion One:My problem is to develop a model to discover the attention pattern(fixation duration) of the visual features regarding the speaker and camera shooting in the ted talk videos that predict audience preference(scoring 1-5 on self-reported attitudes questions: interested, agree, engaging, informative). And my educational goal is to improve audience preference through manipulating attention-related features found in the talk video. My objective is to find the attention pattern that best predict audience preference. Version Two:My problem is to develop a model to discover the visual and audio features regarding the speaker and camera shooting in the ted talk videos that predict the attention pattern(fixation duration and location). My educational goal is to improve audience attention through manipulating visual and audio content features found in the talk video. My objective is to find the visual and audio features that best predict audience attention.I have collected a dataset of 29 participants¡¯ fixation of two ted talk videos and their responses to 4 attitude questions. Currently my priorities are 1) to determine the granularity level of the features I¡¯m coding and entering into the model. For example, how fine-grained should I code the gestures of the speaker, in level of general type(beats, deictics, iconic, metaphoric) or specific shapes and space(in central/peripheral space, high/low span, long/short stroke); 2) to determine the cut-off for defining a fixation(500ms from previous literature); 3) to normalize fixation duration based on total length of the video or specific visual features.See fake dataset in the attached excel.